{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "beta_vae_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJuJ0EJZZ7XVSHe7CFbQZg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcaspari/42_tensorflow_homework/blob/main/disentangled_variational_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDpmX47XkF-s",
        "outputId": "7552e968-60cf-4521-aea2-3c6e9456ce86"
      },
      "source": [
        "!pip install -q tensorflow-probability\r\n",
        "\r\n",
        "# to generate gifs\r\n",
        "!pip install -q imageio\r\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFZoagt3cBwf"
      },
      "source": [
        "from IPython import display\r\n",
        "\r\n",
        "import glob\r\n",
        "import imageio\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import PIL\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_probability as tfp\r\n",
        "import time"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7p3CPv5lky8"
      },
      "source": [
        "# Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnRhVaspcK3x"
      },
      "source": [
        "(train_images, _), (test_images, _) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbLpyD3wf8nx"
      },
      "source": [
        "train_size = 60000\r\n",
        "batch_size = 32\r\n",
        "test_size = 10000"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMLWF1wlcRDT"
      },
      "source": [
        "def preprocess_images(images):\r\n",
        "  images = images.reshape((images.shape[0], 28, 28, 1)) / 255.\r\n",
        "  return np.where(images > .5, 1.0, 0.0).astype('float32')\r\n",
        "\r\n",
        "train_images = preprocess_images(train_images)\r\n",
        "test_images = preprocess_images(test_images)\r\n",
        "\r\n",
        "train_dataset = (tf.data.Dataset.from_tensor_slices(train_images)\r\n",
        "                 .shuffle(train_size).batch(batch_size))\r\n",
        "test_dataset = (tf.data.Dataset.from_tensor_slices(test_images)\r\n",
        "                .shuffle(test_size).batch(batch_size))\r\n"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-jZyc3XlncB"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxn6P1z6nZ1F"
      },
      "source": [
        "class Encoder(tf.keras.Model):\r\n",
        "\r\n",
        "    def __init__(self, latent_dim):\r\n",
        "        super(Encoder, self).__init__()\r\n",
        "        \r\n",
        "        self.input_layer = tf.keras.layers.InputLayer(input_shape = (28, 28, 1))\r\n",
        "        self.conv_32 = tf.keras.layers.Conv2D(\r\n",
        "                filters=32, kernel_size=3, strides=(2, 2), activation='relu')\r\n",
        "        self.conv_64 = tf.keras.layers.Conv2D(\r\n",
        "                filters=64, kernel_size=3, strides=(2, 2), activation='relu')\r\n",
        "        self.flatten = tf.keras.layers.Flatten()\r\n",
        "        self.dense = tf.keras.layers.Dense(latent_dim + latent_dim)\r\n",
        "\r\n",
        "    @tf.function\r\n",
        "    def call(self, x):\r\n",
        "        x = self.input_layer(x)\r\n",
        "        x = self.conv_32(x)\r\n",
        "        x = self.conv_64(x)\r\n",
        "        x = self.flatten(x)\r\n",
        "        x = self.dense(x)\r\n",
        "        return x"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRQi8grqpWCd"
      },
      "source": [
        "class Decoder(tf.keras.Model):\r\n",
        "    \r\n",
        "    def __init__(self, latent_dim):\r\n",
        "        super(Decoder, self).__init__()\r\n",
        "        \r\n",
        "        self.input_layer = tf.keras.layers.InputLayer(input_shape=(latent_dim,))\r\n",
        "        self.dense = tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu)\r\n",
        "        self.reshape = tf.keras.layers.Reshape(target_shape=(7, 7, 32))\r\n",
        "        self.conv_64_trans = tf.keras.layers.Conv2DTranspose(\r\n",
        "                filters=64, kernel_size=3, strides=2, padding='same',\r\n",
        "                activation='relu')\r\n",
        "        self.conv_32_trans = tf.keras.layers.Conv2DTranspose(\r\n",
        "                filters=32, kernel_size=3, strides=2, padding='same',\r\n",
        "                activation='relu')\r\n",
        "        self.conv_1_trans = tf.keras.layers.Conv2DTranspose(\r\n",
        "                filters=1, kernel_size=3, strides=1, padding='same')\r\n",
        "    \r\n",
        "    @tf.function\r\n",
        "    def call(self, x):\r\n",
        "        x = self.input_layer(x)\r\n",
        "        x = self.dense(x)\r\n",
        "        x = self.reshape(x)\r\n",
        "        x = self.conv_64_trans(x)\r\n",
        "        x = self.conv_32_trans(x)\r\n",
        "        x = self.conv_1_trans(x)\r\n",
        "        return x"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vm1J-EAcVgX"
      },
      "source": [
        "class CVAE(tf.keras.Model):\r\n",
        "    \"\"\"Convolutional variational autoencoder.\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, latent_dim):\r\n",
        "        super(CVAE, self).__init__()\r\n",
        "        self.latent_dim = latent_dim\r\n",
        "\r\n",
        "        self.encoder = Encoder(latent_dim)\r\n",
        "        self.decoder = Decoder(latent_dim)\r\n",
        "\r\n",
        "    @tf.function\r\n",
        "    def sample(self, eps=None):\r\n",
        "        if eps is None:\r\n",
        "            eps = tf.random.normal(shape=(100, self.latent_dim))\r\n",
        "        return self.decode(eps, apply_sigmoid=True)\r\n",
        "\r\n",
        "    def encode(self, x):\r\n",
        "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\r\n",
        "        return mean, logvar\r\n",
        "\r\n",
        "    def reparameterize(self, mean, logvar):\r\n",
        "        eps = tf.random.normal(shape=mean.shape)\r\n",
        "        return eps * tf.exp(logvar * .5) + mean\r\n",
        "\r\n",
        "    def decode(self, z, apply_sigmoid=False):\r\n",
        "        logits = self.decoder(z)\r\n",
        "        if apply_sigmoid:\r\n",
        "            probs = tf.sigmoid(logits)\r\n",
        "            return probs\r\n",
        "        return logits"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb6jbWHemJY2"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcTpdN45eNM7"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-4)\r\n",
        "\r\n",
        "\r\n",
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\r\n",
        "    log2pi = tf.math.log(2. * np.pi)\r\n",
        "    return tf.reduce_sum(\r\n",
        "        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\r\n",
        "        axis=raxis)\r\n",
        "\r\n",
        "def kl_divergence(p_encoder, z):\r\n",
        "    q_normal = log_normal_pdf(z, 0., 0.)\r\n",
        "    kl_loss = tf.reduce_sum(\r\n",
        "        p_encoder * tf.math.log(p_encoder/q_normal),\r\n",
        "        axis=[1, 2, 3]\r\n",
        "    )\r\n",
        "    print(f'kl_loss: \\n {kl_loss}')\r\n",
        "    return kl_loss\r\n",
        "\r\n",
        "def criterion(x_logit, x):\r\n",
        "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\r\n",
        "\r\n",
        "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\r\n",
        "    print(f'criterion: \\n {logpx_z}')\r\n",
        "    return logpx_z\r\n",
        "\r\n",
        "def compute_loss(model, x, beta = 4):\r\n",
        "    mean, logvar = model.encode(x)\r\n",
        "    z = model.reparameterize(mean, logvar)\r\n",
        "    x_logit = model.decode(z)\r\n",
        "    loss = -tf.reduce_mean(criterion(x_logit, x) - beta * kl_divergence(x_logit, z))\r\n",
        "    return loss\r\n",
        "\r\n",
        "@tf.function\r\n",
        "def train_step(model, x, optimizer):\r\n",
        "  \"\"\"Executes one training step and returns the loss.\r\n",
        "\r\n",
        "  This function computes the loss and gradients, and uses the latter to\r\n",
        "  update the model's parameters.\r\n",
        "  \"\"\"\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    loss = compute_loss(model, x)\r\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\r\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0bEUBm5fCk0"
      },
      "source": [
        "epochs = 5\r\n",
        "# set the dimensionality of the latent space to a plane for visualization later\r\n",
        "latent_dim = 2\r\n",
        "num_examples_to_generate = 16\r\n",
        "\r\n",
        "# keeping the random vector constant for generation (prediction) so\r\n",
        "# it will be easier to see the improvement.\r\n",
        "random_vector_for_generation = tf.random.normal(\r\n",
        "    shape=[num_examples_to_generate, latent_dim])\r\n",
        "model = CVAE(latent_dim)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwFvcBKmfH0i"
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_sample):\r\n",
        "  mean, logvar = model.encode(test_sample)\r\n",
        "  z = model.reparameterize(mean, logvar)\r\n",
        "  predictions = model.sample(z)\r\n",
        "  fig = plt.figure(figsize=(4, 4))\r\n",
        "\r\n",
        "  for i in range(predictions.shape[0]):\r\n",
        "    plt.subplot(4, 4, i + 1)\r\n",
        "    plt.imshow(predictions[i, :, :, 0], cmap='gray')\r\n",
        "    plt.axis('off')\r\n",
        "\r\n",
        "  # tight_layout minimizes the overlap between 2 sub-plots\r\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\r\n",
        "  plt.show()"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYQWykYMfW2Y"
      },
      "source": [
        "# Pick a sample of the test set for generating output images\r\n",
        "assert batch_size >= num_examples_to_generate\r\n",
        "for test_batch in test_dataset.take(1):\r\n",
        "  test_sample = test_batch[0:num_examples_to_generate, :, :, :]"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "2Lqg230zfaMJ",
        "outputId": "1b36f080-9057-4f6a-d362-e5dd3b23b320"
      },
      "source": [
        "generate_and_save_images(model, 0, test_sample)\r\n",
        "\r\n",
        "for epoch in range(1, epochs + 1):\r\n",
        "  start_time = time.time()\r\n",
        "  for train_x in train_dataset:\r\n",
        "    train_step(model, train_x, optimizer)\r\n",
        "    \r\n",
        "  end_time = time.time()\r\n",
        "\r\n",
        "  loss = tf.keras.metrics.Mean()\r\n",
        "  for test_x in test_dataset:\r\n",
        "    loss(compute_loss(model, test_x))\r\n",
        "  elbo = -loss.result()\r\n",
        "  display.clear_output(wait=False)\r\n",
        "  print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\r\n",
        "        .format(epoch, elbo, end_time - start_time))\r\n",
        "  generate_and_save_images(model, epoch, test_sample)\r\n"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/image.py:452: UserWarning: Warning: converting a masked element to nan.\n",
            "  dv = np.float64(self.norm.vmax) - np.float64(self.norm.vmin)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/image.py:459: UserWarning: Warning: converting a masked element to nan.\n",
            "  a_min = np.float64(newmin)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/image.py:464: UserWarning: Warning: converting a masked element to nan.\n",
            "  a_max = np.float64(newmax)\n",
            "<string>:6: UserWarning: Warning: converting a masked element to nan.\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: UserWarning: Warning: converting a masked element to nan.\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOwAAADnCAYAAAAdFLrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAACt0lEQVR4nO3TQQ0AIBDAMMC/58MCP7KkVbDP9swsoOH8DgDeGRZCDAshhoUQw0KIYSHEsBBiWAgxLIQYFkIMCyGGhRDDQohhIcSwEGJYCDEshBgWQgwLIYaFEMNCiGEhxLAQYlgIMSyEGBZCDAshhoUQw0KIYSHEsBBiWAgxLIQYFkIMCyGGhRDDQohhIcSwEGJYCDEshBgWQgwLIYaFEMNCiGEhxLAQYlgIMSyEGBZCDAshhoUQw0KIYSHEsBBiWAgxLIQYFkIMCyGGhRDDQohhIcSwEGJYCDEshBgWQgwLIYaFEMNCiGEhxLAQYlgIMSyEGBZCDAshhoUQw0KIYSHEsBBiWAgxLIQYFkIMCyGGhRDDQohhIcSwEGJYCDEshBgWQgwLIYaFEMNCiGEhxLAQYlgIMSyEGBZCDAshhoUQw0KIYSHEsBBiWAgxLIQYFkIMCyGGhRDDQohhIcSwEGJYCDEshBgWQgwLIYaFEMNCiGEhxLAQYlgIMSyEGBZCDAshhoUQw0KIYSHEsBBiWAgxLIQYFkIMCyGGhRDDQohhIcSwEGJYCDEshBgWQgwLIYaFEMNCiGEhxLAQYlgIMSyEGBZCDAshhoUQw0KIYSHEsBBiWAgxLIQYFkIMCyGGhRDDQohhIcSwEGJYCDEshBgWQgwLIYaFEMNCiGEhxLAQYlgIMSyEGBZCDAshhoUQw0KIYSHEsBBiWAgxLIQYFkIMCyGGhRDDQohhIcSwEGJYCDEshBgWQgwLIYaFEMNCiGEhxLAQYlgIMSyEGBZCDAshhoUQw0KIYSHEsBBiWAgxLIQYFkIMCyGGhRDDQohhIcSwEGJYCDEshBgWQgwLIYaFEMNCiGEhxLAQYlgIMSyEGBZCDAshhoUQw0KIYSHEsBBiWAgxLIQYFkIMCyGGhRDDQohhIeQCqVAEy1h1lVQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 288x288 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "criterion: \n",
            " Tensor(\"Neg:0\", shape=(32,), dtype=float32)\n",
            "kl_loss: \n",
            " Tensor(\"Sum_2:0\", shape=(32,), dtype=float32)\n",
            "criterion: \n",
            " Tensor(\"Neg:0\", shape=(32,), dtype=float32)\n",
            "kl_loss: \n",
            " Tensor(\"Sum_2:0\", shape=(32,), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-167-8725cca4ffe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtrain_x\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jIiZJUwmwYn"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niu_sfPFffLw"
      },
      "source": [
        "def display_image(epoch_no):\r\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyoGQcSJfhe_"
      },
      "source": [
        "plt.imshow(display_image(epoch))\r\n",
        "plt.axis('off')  # Display images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYxHWRA-foHg"
      },
      "source": [
        "anim_file = 'cvae.gif'\r\n",
        "\r\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\r\n",
        "  filenames = glob.glob('image*.png')\r\n",
        "  filenames = sorted(filenames)\r\n",
        "  for filename in filenames:\r\n",
        "    image = imageio.imread(filename)\r\n",
        "    writer.append_data(image)\r\n",
        "  image = imageio.imread(filename)\r\n",
        "  writer.append_data(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKsuGd0JfqWz"
      },
      "source": [
        "import tensorflow_docs.vis.embed as embed\r\n",
        "embed.embed_file(anim_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7mI1uUrfs2_"
      },
      "source": [
        "def plot_latent_images(model, n, digit_size=28):\r\n",
        "  \"\"\"Plots n x n digit images decoded from the latent space.\"\"\"\r\n",
        "\r\n",
        "  norm = tfp.distributions.Normal(0, 1)\r\n",
        "  grid_x = norm.quantile(np.linspace(0.05, 0.95, n))\r\n",
        "  grid_y = norm.quantile(np.linspace(0.05, 0.95, n))\r\n",
        "  image_width = digit_size*n\r\n",
        "  image_height = image_width\r\n",
        "  image = np.zeros((image_height, image_width))\r\n",
        "\r\n",
        "  for i, yi in enumerate(grid_x):\r\n",
        "    for j, xi in enumerate(grid_y):\r\n",
        "      z = np.array([[xi, yi]])\r\n",
        "      x_decoded = model.sample(z)\r\n",
        "      digit = tf.reshape(x_decoded[0], (digit_size, digit_size))\r\n",
        "      image[i * digit_size: (i + 1) * digit_size,\r\n",
        "            j * digit_size: (j + 1) * digit_size] = digit.numpy()\r\n",
        "\r\n",
        "  plt.figure(figsize=(10, 10))\r\n",
        "  plt.imshow(image, cmap='Greys_r')\r\n",
        "  plt.axis('Off')\r\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvgd_tEXfuxe"
      },
      "source": [
        "plot_latent_images(model, 20)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}